date: September 19, 2016
meeting_type: group
attendance: [chserafi, tsmccorm, mtiruman, adybhav,tm66]
absent: []
excused_absences: [
  {}
  ]
task_progress: [
  {ubit: chserafi, progress: Maintained minutes for previous meetings and submitted them for Sprint #1. Helped to record the YouTube video for Sprint #1.},
  {ubit: mtiruman, progress: Initialized repository and gave access to the other members. Updated the README file.},
  {ubit: adybhav, progress: Understood and discovered the environment.},
  {ubit: tsmccorm, progress: Created a modified Sample executable that produced more manageable output. Helped to record the YouTube video for Sprint #1.},
  {ubit: tm66, progress: Helped to record the YouTube video for Sprint #1.}
  ]
issues: [
  {}
  ]
Notes:  |
  Both Adi and Mani had to leave town shortly after our first meeting, so they did not have access to hardware needed to develop.
  Meeting mainly focused out planning out our course of action for sprint #2.
  It was decided that encoding the software to recognize an open hand and a closed hand would be the best step to take next.
  From there, we would implement standard (non-ASL) counting, and then after that would coming the ASL alphabet (those without motion). 
  Each task would be given about a week deadline, though some are expected to be much faster to implement, in that case we can only be ahead of schedule.
  We determined that we should not use any already-implemented functions from the Leap Motion developer kit, as we felt the output coordinates that are produced in the sample would be enough to work from.
  Planned meetings for the rest of the sprint, hopefully they can stay at a consistent time.
